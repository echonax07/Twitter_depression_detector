{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aware-leisure",
   "metadata": {},
   "source": [
    "## Read the csv file, drop the duplicate(based on converstaionID) and remove unncessary column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "finnish-reference",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Project\\\\Twitter_depression_detector\\\\data\\\\tweet_trend_dataset'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from utils import show_df\n",
    "\n",
    "os.chdir('D:\\\\Project\\\\Twitter_depression_detector\\\\data\\\\tweet_trend_dataset')\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "realistic-evolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads the json generated from the CLI commands above and creates a pandas dataframe\n",
    "tweets_df = pd.read_csv('depression_tweets_2020-03-01.csv')\n",
    "tweets_df=tweets_df.drop_duplicates(subset=['conversationId'])\n",
    "tweets_df=tweets_df.drop(columns=['Unnamed: 0'],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hispanic-eugene",
   "metadata": {},
   "source": [
    "## Search for all the hastags in tweet using regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "front-supplement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                                       []\n",
      "1                                                       []\n",
      "2                                                       []\n",
      "3                                                       []\n",
      "4                                                       []\n",
      "                               ...                        \n",
      "13276                                                   []\n",
      "13277                                                   []\n",
      "13278    [#GratefulnessSunday, #weonlydopositive, #ment...\n",
      "13279    [#JinShinJyutsu, #energyhealing, #quantum, #he...\n",
      "13280                                                   []\n",
      "Name: hashtags, Length: 11768, dtype: object\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b197c84f65a54c218f51a30e4637c5c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Grid(columns_fit='auto', compress_data=True, export_mode='disabled', height='350px', menu={'buttons': [], 'inp…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweets_df['hashtags']=tweets_df.content.str.findall(r'#.*?(?=\\s|$)')\n",
    "print(tweets_df['hashtags'])\n",
    "\n",
    "show_df(tweets_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "urban-rider",
   "metadata": {},
   "source": [
    "## get Count the hashtags and remove the hastags related to medical terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "marine-perspective",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13081    A holistic approach to therapy delves into the...\n",
      "13139    Rants - Episode #3. https://t.co/Jv8iImfBJS vi...\n",
      "13233    The simplest thing yet it could make a huge di...\n",
      "13261    New blog online #mentalhealth #anxiety #bpd #d...\n",
      "13278    You have everything you need already - stay gr...\n",
      "Name: content, dtype: object\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50f6dc1946924212a12428a1153e803e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Grid(columns_fit='auto', compress_data=True, export_mode='disabled', height='350px', menu={'buttons': [], 'inp…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweets_df.hashtags.value_counts().head(20)\n",
    "medical_terms = [\"#mentalhealth\", \"#health\", \"#happiness\", \"#mentalillness\", \"#happy\", \"#joy\", \"#wellbeing\"]\n",
    "mask1 = tweets_df.hashtags.apply(lambda x: any(item for item in medical_terms if item in x))\n",
    "print(tweets_df[mask1].content.tail())\n",
    "tweets_df[mask1==False].content.head(10)\n",
    "tweets_df=tweets_df[mask1==False]\n",
    "\n",
    "show_df(tweets_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-exercise",
   "metadata": {},
   "source": [
    "## remove tweets which contains too many hastags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adult-ceiling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac360094f9d4ca0b0c2bc84e5565e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Grid(columns_fit='auto', compress_data=True, export_mode='disabled', height='350px', menu={'buttons': [], 'inp…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask2 = tweets_df.hashtags.apply(lambda x: len(x) < 4)\n",
    "tweets_df=tweets_df[mask2]\n",
    "tweets_df.hashtags.value_counts().head(20)\n",
    "\n",
    "show_df(tweets_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-prospect",
   "metadata": {},
   "source": [
    "## remove tweets with at mentions as they are sometimes retweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "devoted-linux",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of dataset:  11002\n",
      "Len of dataset:  10903\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "print(\"Len of dataset: \",len(tweets_df))\n",
    "# the mentioned user were stored as string so converted them to list\n",
    "tweets_df['mentionedUsers']=[ast.literal_eval(mentioneduser) if type(mentioneduser)!=float else str(mentioneduser) for mentioneduser in tweets_df['mentionedUsers']]\n",
    "mask3 = tweets_df.mentionedUsers.apply(lambda x: len(x) < 5)\n",
    "tweets_df = tweets_df[mask3]\n",
    "print(\"Len of dataset: \",len(tweets_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "weekly-welsh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bc2780663c446cb9223fb1b1c63f4cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Grid(columns_fit='auto', compress_data=True, export_mode='disabled', height='350px', menu={'buttons': [], 'inp…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_df(tweets_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-tribe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-million",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
