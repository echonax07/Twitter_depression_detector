{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "anticipated-machine",
   "metadata": {},
   "source": [
    "## Read the csv file, drop the duplicate(based on converstaionID) and remove unncessary column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "vulnerable-affect",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Project\\\\Twitter_depression_detector\\\\data'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from utils import show_df\n",
    "\n",
    "os.chdir(r'D:\\Project\\Twitter_depression_detector\\data')\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "resident-washer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads the json generated from the CLI commands above and creates a pandas dataframe\n",
    "tweets_df = pd.read_csv('Depression_merged.csv')\n",
    "tweets_df=tweets_df.drop_duplicates(subset=['conversationId'])\n",
    "tweets_df=tweets_df.drop(columns=['Unnamed: 0'],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frequent-jacket",
   "metadata": {},
   "source": [
    "## Search for all the hastags in tweet using regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "freelance-transition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                                        []\n",
      "1                                                        []\n",
      "2                                                        []\n",
      "3                                                        []\n",
      "4                                                        []\n",
      "                                ...                        \n",
      "140828                                                   []\n",
      "140829                                                   []\n",
      "140830                                              [#gawx]\n",
      "140831    [#essentialoils, #aromatherapy, #essentialoil,...\n",
      "140832                                                   []\n",
      "Name: hashtags, Length: 125128, dtype: object\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b565f806ab0740f89b37983dbe407ec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Grid(columns_fit='auto', compress_data=True, export_mode='disabled', height='350px', menu={'buttons': [], 'inpâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweets_df['hashtags']=tweets_df.content.str.findall(r'#.*?(?=\\s|$)')\n",
    "print(tweets_df['hashtags'])\n",
    "\n",
    "show_df(tweets_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisite-match",
   "metadata": {},
   "source": [
    "## get Count the hashtags and remove the hastags related to medical terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "disabled-present",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140660    Untreated depression can have tragic consequen...\n",
      "140719    New blog online #mentalhealth #anxiety #bpd #d...\n",
      "140782    Got 60 seconds? Take a #mentalhealth minute to...\n",
      "140785    Have you seen our Foundry webpage?Â ðŸ‘‰ https://t...\n",
      "140826    I love this quote! ðŸ’œ\\n\\nRemember to always #Be...\n",
      "Name: content, dtype: object\n"
     ]
    }
   ],
   "source": [
    "tweets_df.hashtags.value_counts().head(20)\n",
    "medical_terms = [\"#mentalhealth\", \"#health\", \"#happiness\", \"#mentalillness\", \"#happy\", \"#joy\", \"#wellbeing\"]\n",
    "mask1 = tweets_df.hashtags.apply(lambda x: any(item for item in medical_terms if item in x))\n",
    "print(tweets_df[mask1].content.tail())\n",
    "tweets_df[mask1==False].content.head(10)\n",
    "tweets_df=tweets_df[mask1==False]\n",
    "\n",
    "#show_df(tweets_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "printable-nowhere",
   "metadata": {},
   "source": [
    "## remove tweets which contains too many hastags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "developing-macedonia",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.map_locations\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'pandas._libs.index.IndexEngine._call_map_locations'\n",
      "Traceback (most recent call last):\n",
      "  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 4588, in pandas._libs.hashtable.PyObjectHashTable.map_locations\n",
      "TypeError: unhashable type: 'list'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]                                                                  105416\n",
       "[#depression]                                                          627\n",
       "[#Depression]                                                          120\n",
       "[#onlinetherapy, #anxiety, #depression]                                 67\n",
       "[#CelebrateHoli2020InVedicWay]                                          62\n",
       "[#VoiceOfDepressionKE]                                                  58\n",
       "[#Anxiety, #Depression]                                                 56\n",
       "[#gawx]                                                                 56\n",
       "[#coronavirus]                                                          51\n",
       "[#Anxiety, #Depression.]                                                48\n",
       "[#depression, #anxiety]                                                 43\n",
       "[#MentalHealthMatters]                                                  42\n",
       "[#Anxiety, #Depression, #Addiction]                                     41\n",
       "[#anxiety, #depression]                                                 40\n",
       "[#Holi2020WithVedicMethod]                                              37\n",
       "[#FinancialCrisisTour, #WallStreetInsiderTour, #personalfinance]        33\n",
       "[#MaYouthsPleaseSpeakUpPlease]                                          29\n",
       "[#COVID19]                                                              28\n",
       "[#]                                                                     27\n",
       "[#Depression, #MentalHealth, #Children]                                 27\n",
       "Name: hashtags, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask2 = tweets_df.hashtags.apply(lambda x: len(x) < 4)\n",
    "tweets_df=tweets_df[mask2]\n",
    "tweets_df.hashtags.value_counts().head(20)\n",
    "\n",
    "#show_df(tweets_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "front-printer",
   "metadata": {},
   "source": [
    "## remove tweets with @ mentions as they are sometimes retweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "temporal-antenna",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of dataset:  116846\n",
      "Len of dataset:  115785\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "print(\"Len of dataset: \",len(tweets_df))\n",
    "# the mentioned user were stored as string so converted them to list\n",
    "tweets_df['mentionedUsers']=[ast.literal_eval(mentioneduser) if type(mentioneduser)!=float else str(mentioneduser) for mentioneduser in tweets_df['mentionedUsers']]\n",
    "mask3 = tweets_df.mentionedUsers.apply(lambda x: len(x) < 5)\n",
    "tweets_df = tweets_df[mask3]\n",
    "print(\"Len of dataset: \",len(tweets_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "martial-afghanistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_df(tweets_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "backed-disaster",
   "metadata": {},
   "source": [
    "## Remove tweets containing URLS as they might be promotional msgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "administrative-empire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115785\n",
      "95842\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "print(len(tweets_df))\n",
    "tweets_df['outlinks']=[ast.literal_eval(outlink) for outlink in tweets_df['outlinks']]\n",
    "mask4 = tweets_df.outlinks.apply(lambda x: len(x)==0)\n",
    "tweets_df = tweets_df[mask4]\n",
    "print(len(tweets_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "difficult-booking",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_df(tweets_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parliamentary-perry",
   "metadata": {},
   "source": [
    "## Feature engineering, a column featuring count of the mentioneduser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "small-azerbaijan",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['mentionedUserCount']=[len(mentionedUser) if type(mentionedUser)==list else 0 for mentionedUser in tweets_df['mentionedUsers']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "facial-dealer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_df(tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "narrow-chicken",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_df.to_csv('cleaned_tweets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-control",
   "metadata": {},
   "source": [
    "## see the difference between two columns content and renderedcontent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "automatic-invasion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95842\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for i in range(len(tweets_df)):\n",
    "    if tweets_df.iloc[i]['renderedContent']==tweets_df.iloc[i]['content']:\n",
    "        count+=1\n",
    "print(count)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scientific-joint",
   "metadata": {},
   "source": [
    "## select the useful columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "artificial-passage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.1', 'url', 'date', 'content', 'renderedContent', 'id',\n",
       "       'user', 'outlinks', 'tcooutlinks', 'replyCount', 'retweetCount',\n",
       "       'likeCount', 'quoteCount', 'conversationId', 'lang', 'source',\n",
       "       'sourceUrl', 'sourceLabel', 'media', 'retweetedTweet', 'quotedTweet',\n",
       "       'mentionedUsers', 'hashtags', 'mentionedUserCount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "committed-wildlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_cleaned_df=tweets_df[['url','date','user','renderedContent','replyCount','retweetCount','likeCount','quoteCount','mentionedUserCount']]\n",
    "tweets_cleaned_df=tweets_df[['renderedContent','mentionedUserCount']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "handy-lover",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_df(tweets_cleaned_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architectural-history",
   "metadata": {},
   "source": [
    "## Exporting the cleaned tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "little-generic",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_cleaned_df.to_csv('cleaned_merged_depression_tweets.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subsequent-walker",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
